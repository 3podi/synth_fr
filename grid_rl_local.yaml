# @package _global_
defaults:
  - _self_

size: 10
size_generation: 10 #number of prompts to use to generate sequences (4 answers for prompt by default)
step: dpo
group_id: rl_qwen_4b
run_id: ???
sts_model: Qwen/Qwen2.5-7B-Instruct #microsoft/MediPhi-Instruct #Qwen/Qwen3-8B #google/gemma-2-9b-it #Alibaba-NLP/gte-multilingual-base #FremyCompany/BioLORD-2023
domain: health
private_path: datasets/health/model=Qwen-Qwen3-4B-Instruct-2507_size=10/private_seed.parquet #datasets/health/model=meta-llama-Llama-3.2-1B-Instruct_size=1001/private_seed.parquet #datasets/health/model=meta-llama-llama-2-7b-hf_size=1001/private_seed.parquet
tp: 1
pp: 1
model_name: Qwen/Qwen3-4B-Instruct-2507 #meta-llama/Llama-3.2-1B-Instruct #meta-llama/llama-2-7b-hf

sorting: "avg"
train_steps: "dpo"

# Random generation
csv_path: ../cim_synonymes.csv
num_samples_rand_gen: 100
max_codes: 5
max_kws: 1

scripts:
  sft: training_steps/sft/train.py
  dpo: training_steps/alignment/dpo2.py
  merge: training_steps/generation/merge_adapters.py
  generation: training_steps/generation/run.py
  random_generation: training_steps/generation/random_gen.py
  score: training_steps/score/run.py
  filter: training_steps/filter/run.py
  classificaion: training_steps/classification/train.py

lora_path: "lora/"
start_it: 1
end_it: 3